{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DETECTING FINGERS :\n",
    "\n",
    "1.Defining an ROI where fingers will be detected.\n",
    "\n",
    "2.Running background analysis(Getting average background value) to study the background so that elements in the backgrounds would not be mistook as fingers.\n",
    "\n",
    "3.Finding the largest contour in the ROI assuming it to be the hand.\n",
    "\n",
    "4.Obtaining the topmost , rightend and leftend (extreme points) and finding the co-ordinates of the center of the hand by using convexHull() method.\n",
    "\n",
    "5.Finding the euclidean distances between the center and the extreme points and storing the maximum one.\n",
    "\n",
    "5.Creating a circular ROI with radius being 90% of the maximum euclidean distance and masking it on the thresholded version.\n",
    "\n",
    "6.All the external contours are then detected in the imaginary circular ROI and contours which lie in the limit_points(circumference of the circular ROI) and out_of_wrist (Height greater than  wrist points) are detected as fingers and no.of finger counters are counted hence giving the no.of fingers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating required global variables\n",
    "\n",
    "bg = None\n",
    "accumulated_wt = 1.5 #Default values\n",
    "\n",
    "#Defining the position of the ROI\n",
    "roi_top = 20\n",
    "roi_bottom = 300\n",
    "roi_right = 300\n",
    "roi_left = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get the background and get the accumulated weights\n",
    "\n",
    "def get_bg_wt(frame,accumulated_wt):\n",
    "    global bg\n",
    "    \n",
    "    if bg is None:\n",
    "        bg = frame.copy().astype('float')\n",
    "        return None\n",
    "    cv2.accumulateWeighted(frame,bg,accumulated_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segmenting hand based on ROI\n",
    "\n",
    "def segment_hand(frame,threshold = 25):\n",
    "    \n",
    "    diff = cv2.absdiff(bg.astype('uint8'),frame)\n",
    "\n",
    "    ret,thresh = cv2.threshold(diff,threshold,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "    contours,_ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     _,contours = cv2.findContours(thresh.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if len(contours) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        hand_segment = max(contours,key = cv2.contourArea)\n",
    "    return(thresh,hand_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_fingers(thresh,hand_segment):\n",
    "    conv_hull = cv2.convexHull(hand_segment)\n",
    "    \n",
    "    conv_hull = cv2.convexHull(hand_segment)\n",
    "    \n",
    "    top = conv_hull(conv_hull[:,:,1].argmin()[0])\n",
    "    bottom = conv_hull(conv_hull[:,:,1].argmax()[0])\n",
    "    left = conv_hull(conv_hull[:,:,0].argmin()[0])\n",
    "    right = conv_hull(conv_hull[:,:,0].argmax()[0])\n",
    "    \n",
    "    cX  = (left[0]+right[0])//2\n",
    "    cY  = (top[1]+bottom[1])//2\n",
    "    \n",
    "    distance = pairwise.euclidean_distances([cX,cY],Y = [left,right,top,bottom])[0]\n",
    "    max_dist = distance.max()\n",
    "    radius = int(0.8*max_dist)\n",
    "    circumference  = (2*np.pi*radius)\n",
    "    \n",
    "    circular_roi = np.zeros(thresh[:2],dtype = 'uint8')\n",
    "    cv2.cirlce(circular_roi,(cX,cY),radius,255,10)\n",
    "    circular_roi = cv2.bitwise_and(thresh,thresh,mask = circular_roi)\n",
    "    \n",
    "    fing_cont,_ = cv2.findContours(circular_roi,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for cont in fing_cont:\n",
    "        (x,y,w,h) = cv2.boundingRect(cont)\n",
    "        \n",
    "        out_of_wrist = (cY+(cY*0.25)) > (y+h)\n",
    "        \n",
    "        limit_points = ((0.25*circumference) > cnt.shape[0])\n",
    "        \n",
    "        if out_of_wrist and limit_points :\n",
    "            count +=1\n",
    "            \n",
    "    return count\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-k8sx3e60\\opencv\\modules\\imgproc\\src\\contours.cpp:197: error: (-210:Unsupported format or combination of formats) [Start]FindContours supports only CV_8UC1 images when mode != CV_RETR_FLOODFILL otherwise supports CV_32SC1 images only in function 'cvStartFindContours_Impl'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-9055ddb9e50d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m                 \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mputText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe_copy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Work In Progress\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFONT_HERSHEY_SIMPLEX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mhand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msegment_hand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhand\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhand_segment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-c159bcb261f3>\u001b[0m in \u001b[0;36msegment_hand\u001b[1;34m(frame, threshold)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthresh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mcontours\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindContours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthresh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRETR_EXTERNAL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHAIN_APPROX_SIMPLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;31m#     _,contours = cv2.findContours(thresh.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-k8sx3e60\\opencv\\modules\\imgproc\\src\\contours.cpp:197: error: (-210:Unsupported format or combination of formats) [Start]FindContours supports only CV_8UC1 images when mode != CV_RETR_FLOODFILL otherwise supports CV_32SC1 images only in function 'cvStartFindContours_Impl'\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "num_frames = 0\n",
    "\n",
    "while True:\n",
    "        ret,frame = cap.read()\n",
    "        frame_copy = frame.copy()\n",
    "        \n",
    "        roi = frame[roi_top:roi_bottom,roi_right:roi_left]\n",
    "        gray = cv2.cvtColor(frame_copy,cv2.COLOR_BGR2RGB)\n",
    "        gray = cv2.GaussianBlur(gray,(7,7),0)\n",
    "        \n",
    "        if num_frames <  60:\n",
    "            get_bg_wt(gray,accumulated_wt)\n",
    "            \n",
    "            if num_frames<=59:\n",
    "                cv2.putText(frame_copy,\"Work In Progress\",(200,300),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),4)\n",
    "        else:\n",
    "            hand = segment_hand(gray)\n",
    "            if hand is not None:\n",
    "                threshold,hand_segment = hand\n",
    "                cv2.drawContours(frame_copy,[hand_segment],-1,(255,0,0),5)\n",
    "                \n",
    "                fingers_count = count_fingers(threshold,hand_segment)\n",
    "                cv2.putText(frame_copy,str(fingers_count),(70,50),cv2.FONT_HERSHEY_SIMPLEX,(255,255,255),3)\n",
    "                \n",
    "                cv2.imshow('GrayScale ROI',threshold)\n",
    "                \n",
    "        cv2.rectangle(frame_copy,(roi_right,roi_top),(roi_left,roi_bottom),(0,0,255),3)\n",
    "        num_frames += 1\n",
    "        cv2.imshow('Finger_count',frame_copy)\n",
    "        k = cv2.waitKey(1) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
